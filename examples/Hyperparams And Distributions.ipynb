{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparams And Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This page introduces the hyperparams, and distributions in Neuraxle. You can find [Hyperparams Distribution API here](https://www.neuraxle.org/stable/api/neuraxle.hyperparams.distributions.html), and \n",
    "[Hyperparameter Samples API here](https://www.neuraxle.org/stable/api/neuraxle.hyperparams.space.html).\n",
    "\n",
    "Hyperparameter is a parameter drawn from a prior distribution. In Neuraxle, we have a few built-in distributions, and we are also compatible with scipy distributions. \n",
    "\n",
    "Create a [Uniform Distribution](https://www.neuraxle.org/stable/api/neuraxle.hyperparams.distributions.html#neuraxle.hyperparams.distributions.Uniform):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neuraxle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-99c432acc3f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mneuraxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m hd = Uniform(\n\u001b[1;32m      4\u001b[0m     \u001b[0mmin_included\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmax_included\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'neuraxle'"
     ]
    }
   ],
   "source": [
    "from neuraxle.hyperparams.distributions import Uniform\n",
    "\n",
    "hd = Uniform(\n",
    "    min_included=-10, \n",
    "    max_included=10, \n",
    "    null_default_value=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the random variable using [rvs](https://www.neuraxle.org/stable/api/neuraxle.hyperparams.distributions.html#neuraxle.hyperparams.distributions.HyperparameterDistribution.rvs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = hd.rvs()\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nullify the random variable using [nullify](https://www.neuraxle.org/stable/api/neuraxle.hyperparams.distributions.html#neuraxle.hyperparams.distributions.HyperparameterDistribution.nullify):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nullified_sample = hd.nullify()\n",
    "assert nullified_sample == hd.null_default_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the probability distribution function value at `x` using [pdf](https://www.neuraxle.org/stable/api/neuraxle.hyperparams.distributions.html#neuraxle.hyperparams.distributions.HyperparameterDistribution.pdf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = hd.pdf(1)\n",
    "print('pdf: {}'.format(pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the cumulative probability distribution function value at `x` using [cdf](https://www.neuraxle.org/stable/api/neuraxle.hyperparams.distributions.html#neuraxle.hyperparams.distributions.HyperparameterDistribution.cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = hd.cdf(1)\n",
    "print('cdf: {}'.format(cdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting And Updating Hyperparams\n",
    "\n",
    "\n",
    "In Neuraxle, each step has hyperparams of type [HyperparameterSamples](https://www.neuraxle.org/stable/api/neuraxle.hyperparams.space.html#neuraxle.hyperparams.space.HyperparameterSamples), and spaces of type [HyperparameterSpace](https://www.neuraxle.org/stable/api/neuraxle.hyperparams.distributions.html#neuraxle.hyperparams.distributions.HyperparameterDistribution).  \n",
    "\n",
    "Consider a simple pipeline that contains 2 MultiplyByN steps, and one PCA component inside a nested pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from neuraxle.hyperparams.distributions import RandInt\n",
    "from neuraxle.hyperparams.space import HyperparameterSpace, HyperparameterSamples\n",
    "from neuraxle.pipeline import Pipeline\n",
    "from neuraxle.steps.numpy import MultiplyByN\n",
    "\n",
    "p = Pipeline([\n",
    "    ('step1', MultiplyByN(2)),\n",
    "    ('step2', MultiplyByN(2)),\n",
    "    Pipeline([\n",
    "        PCA(n_components=4)\n",
    "    ])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set or update the hyperparams, and spaces by doing the following:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.set_hyperparams(HyperparameterSamples({\n",
    "    'step1__multiply_by': 42,\n",
    "    'step2__multiply_by': -10,\n",
    "    'Pipeline__PCA__n_components': 2\n",
    "}))\n",
    "\n",
    "p.update_hyperparams(HyperparameterSamples({\n",
    "    'Pipeline__PCA__n_components': 3\n",
    "}))\n",
    "\n",
    "p.set_hyperparams_space(HyperparameterSpace({\n",
    "    'step1__multiply_by': RandInt(42, 50),\n",
    "    'step2__multiply_by': RandInt(-10, 0),\n",
    "    'Pipeline__PCA__n_components': RandInt(2, 3)\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sample the space of random variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = p.get_hyperparams_space().rvs()\n",
    "\n",
    "assert 42 <= samples['step1__multiply_by'] <= 50\n",
    "assert -10 <= samples['step2__multiply_by'] <= 0\n",
    "assert samples['Pipeline__PCA__n_components'] in [2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get all hyperparams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = p.get_hyperparams()\n",
    "\n",
    "assert 42 <= samples['step1__multiply_by'] <= 50\n",
    "assert -10 <= samples['step2__multiply_by'] <= 0\n",
    "assert samples['Pipeline__PCA__n_components'] in [2, 3]\n",
    "assert p['Pipeline']['PCA'].get_wrapped_sklearn_predictor().n_components in [2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuraxle Custom Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy Distributions \n",
    "\n",
    "To define a scipy distribution that is compatible with Neuraxle, you need to wrap the scipy distribution with ScipyDistributionWrapper: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuraxle.hyperparams.scipy_distributions import ScipyDistributionWrapper\n",
    "\n",
    "hd = ScipyDistributionWrapper(\n",
    "    scipy_distribution=randint(low=min_included, high=max_included),\n",
    "    null_default_value=null_default_value\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Distributions\n",
    "For discrete distribution that inherit from [rv_discrete](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_discrete.html#scipy.stats.rv_discrete), you only need to implement _pmf. The rest is taken care of magically by scipy.  \n",
    "\n",
    "For example, here is a discrete poisson distribution: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoissonScipyDistribution(rv_discrete):\n",
    "    def _pmf(self, k, mu):\n",
    "        return math.exp(-mu) * mu ** k / factorial(k)\n",
    "\n",
    "class Poisson(ScipyDistributionWrapper):\n",
    "    def __init__(self, min_included: float, max_included: float, null_default_value: float = None, mu=0.6):\n",
    "        super().__init__(\n",
    "            scipy_distribution=PoissonScipyDistribution(\n",
    "                a=min_included,\n",
    "                b=max_included,\n",
    "                name='poisson'\n",
    "            ),\n",
    "            null_default_value=null_default_value,\n",
    "            mu=mu\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Distributions\n",
    "\n",
    "For continous distribution that inherit from [rv_continuous](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.html), you only need to implement _pdf function. The rest is taken care of magically by scipy.  \n",
    "\n",
    "For example, here is a continous gaussian distribution: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianScipyDistribution(rv_continuous):\n",
    "    def _pdf(self, x):\n",
    "        return math.exp(-x ** 2 / 2.) / np.sqrt(2.0 * np.pi)\n",
    "\n",
    "\n",
    "class Gaussian(ScipyDistributionWrapper):\n",
    "    def __init__(self, min_included: int, max_included: int, null_default_value: float = None):\n",
    "        ScipyDistributionWrapper.__init__(\n",
    "            self,\n",
    "            scipy_distribution=GaussianScipyDistribution(\n",
    "                name='gaussian',\n",
    "                a=min_included,\n",
    "                b=max_included\n",
    "            ),\n",
    "            null_default_value=null_default_value\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Arguments \n",
    "\n",
    "If you want to add additional arguments to the _pdf, and _cmf methods, you have to override the _argcheck method from scipy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogNormalScipyDistribution(rv_continuous):\n",
    "    def _pdf(self, x, log2_space_mean, log2_space_std):\n",
    "        if x <= 0:\n",
    "            return 0.\n",
    "\n",
    "        cdf_min = 0.\n",
    "        cdf_max = 1.\n",
    "\n",
    "        pdf_x = 1 / (x * math.log(2) * log2_space_std * math.sqrt(2 * math.pi)) * math.exp(\n",
    "            -(math.log2(x) - log2_space_mean) ** 2 / (2 * log2_space_std ** 2))\n",
    "        return pdf_x / (cdf_max - cdf_min)\n",
    "\n",
    "    def _argcheck(self, *args):\n",
    "        cond = 1\n",
    "        for arg in args:\n",
    "            cond = np.logical_and(\n",
    "                cond,\n",
    "                isinstance(arg, np.ndarray) and \\\n",
    "                (arg.dtype == np.float or arg.dtype == np.int)\n",
    "            )\n",
    "        return cond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy methods\n",
    "\n",
    "All of the scipy distribution methods are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = get_many_samples_for(hd)\n",
    "\n",
    "for s in samples:\n",
    "    assert type(s) == int\n",
    "samples_mean = np.abs(np.mean(samples))\n",
    "assert samples_mean < 1.0\n",
    "assert min(samples) >= -10.0\n",
    "assert max(samples) <= 10.0\n",
    "\n",
    "assert hd.pdf(-11) == 0.\n",
    "assert abs(hd.pdf(-10) - 1 / (10 + 10 + 1)) < 1e-6\n",
    "assert abs(hd.pdf(0) - 1 / (10 + 10 + 1)) < 1e-6\n",
    "assert hd.pdf(0.5) == 0.\n",
    "assert abs(hd.pdf(10) - 1 / (10 + 10 + 1)) < 1e-6\n",
    "assert hd.pdf(11) == 0.\n",
    "\n",
    "assert hd.cdf(-10.1) == 0.\n",
    "assert abs(hd.cdf(-10) - 1 / (10 + 10 + 1)) < 1e-6\n",
    "assert abs(hd.cdf(0) - (0 + 10 + 1) / (10 + 10 + 1)) < 1e-6\n",
    "assert abs(hd.cdf(5) - (5 + 10 + 1) / (10 + 10 + 1)) < 1e-6\n",
    "assert abs(hd.cdf(10) - 1.) < 1e-6\n",
    "assert hd.cdf(10.1) == 1.\n",
    "\n",
    "assert hd.logpdf(5) == -13.418938533204672\n",
    "assert hd.logcdf(5) == -0.6931477538632531\n",
    "assert hd.sf(5) == 0.5000002866515718\n",
    "assert hd.logsf(5) == -0.693146607256966\n",
    "assert np.all(hd.ppf([0.0, 0.01, 0.05, 0.1, 1 - 0.10, 1 - 0.05, 1 - 0.01, 1.0], 10))\n",
    "assert hd.isf(q=0.5) == 8.798228093189323\n",
    "assert hd.moment(2) == 50.50000000091249\n",
    "assert hd.stats()[0]\n",
    "assert hd.stats()[1]\n",
    "assert np.array_equal(hd.entropy(), np.array(0.7094692666023363))\n",
    "assert hd.median()\n",
    "assert hd.mean() == 5.398942280397029\n",
    "assert hd.std() == 4.620759921685374\n",
    "assert hd.var() == 21.35142225385382\n",
    "assert hd.expect() == 0.39894228040143276\n",
    "interval = hd.interval(alpha=[0.25, 0.50])\n",
    "assert np.all(interval[0])\n",
    "assert np.all(interval[1])\n",
    "assert hd.support() == (0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKLearn Hyperparams\n",
    "\n",
    "SKLearnWrapper wraps sklearn predictors so that they can be compatible with Neuraxle. When you set the hyperparams of an SKLearnWrapper, it automatically sets the params of the sklearn predictor for you: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuraxle.hyperparams.distributions import Choice\n",
    "from neuraxle.hyperparams.distributions import RandIn\n",
    "from neuraxle.hyperparams.space import HyperparameterSpace\n",
    "from neuraxle.steps.sklearn import SKLearnWrapper\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "decision_tree_classifier = SKLearnWrapper(\n",
    "    DecisionTreeClassifier(), \n",
    "    HyperparameterSpace({\n",
    "        'criterion': Choice(['gini', 'entropy']), \n",
    "        'splitter': Choice(['best', 'random']),\n",
    "        'min_samples_leaf': RandInt(2, 5), \n",
    "        'min_samples_split': RandInt(1, 3) \n",
    "    })\n",
    ").set_hyperparams(HyperparameterSamples({\n",
    "    'criterion': 'gini', \n",
    "    'splitter': 'best',\n",
    "    'min_samples_leaf': 3, \n",
    "    'min_samples_split': 3 \n",
    "}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuraxle",
   "language": "python",
   "name": "neuraxle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
