{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Saving And Lifecycle \n",
    "\n",
    "<p style=\"font-size:18px\">This page introduces the concept of lifecycle in a Neuraxle BaseStep. You can find a deailed component API reference here.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lifecycle\n",
    "<img src=\"images/lifecycle.png\" style=\"max-width:600px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **BaseStep.__init__()**: This is where you initialize all of your props, and fitted state. \n",
    "2. **set_hyperparams()**:\n",
    "3. **setup()**: Initialize the step before it runs. Only from here and not before that heavy things should be created (e.g.: things inside GPU), and NOT in the constructor.\n",
    "4. **fit(data_inputs, expected_outputs)**: Fit step with the given data inputs, and expected outputs.\n",
    "\n",
    "5. **transform(data_inputs)**: Transform given data inputs.\n",
    "6. **save(context, full_dump)**: Save step using the execution context to create the directory to save the step into.\n",
    "7. **teardown()**: Teardown step after program execution. Inverse of setup, and it should clear memory. Override this method if you need to clear memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Neuraxle, each step has a list of savers that can load, and save steps. Steps are saved using the execution context to create the directory to save the step into. The saving happens by looping through all of the step savers in the reversed order. \n",
    "\n",
    "The cool thing about this is that you don't even need the source code to load your steps. This enables a lot of thing like parallel processing, and distributed computing. \n",
    "\n",
    "### Saver\n",
    "\n",
    "Some savers just save parts of objects, some save it all or what remains.\n",
    "The JoblibStepSaver has to be called last because it needs a\n",
    "stripped version of the step.\n",
    "\n",
    "You might need to create your own saver if you are using a step that is not serializable. For instance, this will most likely happen if the step is a deep learning model. \n",
    "\n",
    "Fortunately, we have already built a set of savers for tensorflow 1, and 2 in [Neuraxle-Tensorflow](https://github.com/Neuraxio/Neuraxle-TensorFlow). We plan to do the same thing for Pytorch soon.\n",
    "\n",
    "Here is an example of a custom saver that strips the multiprocessing Queue from a step called SequentialQueuedPipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObservableQueueStepSaver(BaseSaver):\n",
    "    def save_step(self, step: 'BaseStep', context: 'ExecutionContext') -> 'BaseStep':\n",
    "        step.queue = None\n",
    "        step.observers = []\n",
    "        return step\n",
    "\n",
    "    def can_load(self, step: 'BaseStep', context: 'ExecutionContext'):\n",
    "        return True\n",
    "\n",
    "    def load_step(self, step: 'BaseStep', context: 'ExecutionContext') -> 'BaseStep':\n",
    "        step.queue = Queue()\n",
    "        return step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Context\n",
    "\n",
    "Execution context object contains all of the pipeline hierarchy steps.\n",
    "First item in parents is root, second is nested, and so on. This is like a stack. Note: You should not have to worry about pushing steps to the context because it is already done for you in the handler methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Dump Saving\n",
    "\n",
    "To save the full pipeline even if steps are not invalidated or initialized, you can use full dump saving: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = 'saved_pipeline_name'\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    TrainOnlyWrapper(DataShuffler()),\n",
    "    OutputTransformerWrapper(NumpyRavel()),\n",
    "    SKLearnWrapper(LogisticRegression(), HyperparameterSpace({\n",
    "        'C': LogUniform(0.01, 10.0), \n",
    "        'fit_intercept': Boolean(), \n",
    "        'dual': Boolean(),\n",
    "        'penalty': Choice(['l1', 'l2']), \n",
    "        'max_iter': RandInt(20, 200)\n",
    "    }))\n",
    "], cache_folder='cache_folder').set_name(PIPELINE_NAME)\n",
    "\n",
    "pipeline, outputs = pipeline.fit_transform(DATA_INPUTS, EXPECTED_OUTPUTS)\n",
    "pipeline.save(ExecutionContext(tmpdir), full_dump=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Dump Loading\n",
    "\n",
    "To Load a full pipeline without any source code, you can load the full dump using the execution context load method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ExecutionContext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bf30bce54c6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExecutionContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmpdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPIPELINE_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_INPUTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ExecutionContext' is not defined"
     ]
    }
   ],
   "source": [
    "loaded_pipeline = ExecutionContext(tmpdir).load(PIPELINE_NAME)\n",
    "outputs = pipeline.transform(DATA_INPUTS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neuraxle",
   "language": "python",
   "name": "neuraxle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
