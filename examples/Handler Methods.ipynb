{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handler Methods\n",
    "\n",
    "<p style=\"font-size:18px\">Handler methods define the skeleton of the execution algorithm. It let's steps override some part of the algorithm without changing the structure. It makes it possible to build really powerful steps that can edit, and change the execution flow. You can find a detailed BaseStep API reference here.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/handler_methods.png\" style=\"width=:50\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following handle methods are available for each step: \n",
    "\n",
    "\n",
    "### handle_fit_transform\n",
    "\n",
    "1. _will_process(data_container, context): Apply side effects before any step method.\n",
    "2. _will_fit_transform(data_container, context): Apply side effects before fit_transform\n",
    "3. _fit_transform_data_container(data_container, context): Fit transform data container.\n",
    "4. _did_fit_transform(data_container, context): Apply side effects after fit_transform.\n",
    "5. _did_process(data_container, context): Apply side effects after any step method.\n",
    "\n",
    "### handle_fit\n",
    "\n",
    "1. _will_process(data_container, context): Apply side effects before any step method.\n",
    "2. _will_fit_transform(data_container, context): Apply side effects before fit.\n",
    "3. _fit_data_container(data_container, context): Fit data container.\n",
    "4. _did_fit(data_container, context): Apply side effects after fit.\n",
    "\n",
    "### handle_transform\n",
    "\n",
    "1. _will_process(data_container, context): Apply side effects before any step method.\n",
    "2. _will_transform(data_container, context): Apply side effects before transform.\n",
    "3. _transform_data_container(data_container, context): Fit transform data container.\n",
    "4. _did_transform(data_container, context): Apply side effects after transform. \n",
    "5. _did_process(data_container, context): Apply side effects after any step method.\n",
    "\n",
    "### When to use handler methods ? \n",
    "\n",
    "When you need to apply side effects, or change the execution flow:\n",
    "\n",
    "- Edit the DataContainer\n",
    "- Call a method on a step\n",
    "- Mini-Batching\n",
    "- Caching\n",
    "- etc.\n",
    "\n",
    "### HandleOnlyMixin\n",
    "\n",
    "Inherit from HandleOnlyMixin, to only implement the handler methods, and forbid implementing fit or transform or fit_transform without the handles.\n",
    "\n",
    "### ForceHandleMixin\n",
    "\n",
    "Inherit from ForceHandleMixin, to automatically calls handle methods in the transform, fit, and fit_transform methods. A step might have to be forced to pass through the lifecycle methods. This is true for all of the steps that can be called from the outside world. For example, you might want to transform all of the data inside the data container. \n",
    "\n",
    "### ForceHandleOnlyMixin\n",
    "\n",
    "Inherit from ForceHandleOnlyMixin to require the implementation of handler methods, AND automatically call handle methods in the transform, fit, and fit_transform methods.\n",
    "\n",
    "\n",
    "## Examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToNumpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neuraxle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-749ad56c0fe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mneuraxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataContainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExecutionContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mForceHandleMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mToNumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mForceHandleMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0mConvert\u001b[0m \u001b[0mdata\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'neuraxle'"
     ]
    }
   ],
   "source": [
    "from neuraxle.base import BaseStep, DataContainer, ExecutionContext, ForceHandleMixin\n",
    "\n",
    "class ToNumpy(ForceHandleMixin, BaseStep):\n",
    "    \"\"\"\n",
    "    Convert data inputs, and expected outputs to a numpy array.\n",
    "    \"\"\"\n",
    "\n",
    "    def _will_process(self, data_container: DataContainer, context: ExecutionContext) -> (DataContainer, ExecutionContext):\n",
    "        return data_container.to_numpy(), context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Expected Outputs\n",
    "Consider a wrapper step that would transform the expected outputs instead of the data inputs.\n",
    "\n",
    "Create such a step in 4 easy steps (toudoum tish) : \n",
    "\n",
    "1. Create a step that inherits from **ForceHandleOnlyMixin**, and **MetaStepMixin**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuraxle.base import ExecutionContext, BaseStep, MetaStepMixin, ForceHandleOnlyMixin\n",
    "from neuraxle.data_container import DataContainer\n",
    "\n",
    "\n",
    "class OutputTransformerWrapper(ForceHandleOnlyMixin, MetaStepMixin, BaseStep):\n",
    "    def __init__(self, wrapped, cache_folder_when_no_handle=None):\n",
    "        BaseStep.__init__(self)\n",
    "        MetaStepMixin.__init__(self, wrapped)\n",
    "        ForceHandleOnlyMixin.__init__(self, cache_folder_when_no_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement **_transform_data_container**: \n",
    "\n",
    "Pass expected outputs to the wrapped step **handle_transform** method. Update the data container expected outputs with the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _transform_data_container(self, data_container: DataContainer, context: ExecutionContext) -> DataContainer:\n",
    "    new_expected_outputs_data_container = self.wrapped.handle_transform(\n",
    "        DataContainer(\n",
    "            data_inputs=data_container.expected_outputs, \n",
    "            current_ids=data_container.current_ids, \n",
    "            expected_outputs=None\n",
    "        ), \n",
    "        context\n",
    "    )\n",
    "    data_container.set_expected_outputs(new_expected_outputs_data_container.data_inputs)\n",
    "\n",
    "    return data_container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement **_fit_data_container**: \n",
    "\n",
    "Pass expected outputs to the wrapped step **handle_fit** method. Update the data container expected outputs with the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_data_container(self, data_container: DataContainer, context: ExecutionContext) -> (BaseStep, DataContainer):\n",
    "    self.wrapped = self.wrapped.handle_fit(\n",
    "        DataContainer(\n",
    "            data_inputs=data_container.expected_outputs, \n",
    "            current_ids=data_container.current_ids, \n",
    "            expected_outputs=None),\n",
    "        context\n",
    "    )\n",
    "\n",
    "    return self, data_container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implement **_fit_transform_data_container**: \n",
    "\n",
    "Pass expected outputs to the wrapped step **handle_fit_transform** method.\n",
    "Update the data container expected outputs with the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_transform_data_container(self, data_container: DataContainer, context: ExecutionContext) -> (BaseStep, DataContainer):\n",
    "    self.wrapped, new_expected_outputs_data_container = self.wrapped.handle_fit_transform(\n",
    "        DataContainer(\n",
    "            data_inputs=data_container.expected_outputs, \n",
    "            current_ids=data_container.current_ids,\n",
    "            expected_outputs=None\n",
    "        ),\n",
    "        context\n",
    "    )\n",
    "    data_container.set_expected_outputs(new_expected_outputs_data_container.data_inputs)\n",
    "\n",
    "    return self, data_container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results looks like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuraxle.base import ExecutionContext, BaseStep, MetaStepMixin, ForceHandleOnlyMixin\n",
    "from neuraxle.data_container import DataContainer\n",
    "\n",
    "\n",
    "class OutputTransformerWrapper(ForceHandleOnlyMixin, MetaStepMixin, BaseStep):\n",
    "    def __init__(self, wrapped, cache_folder_when_no_handle=None):\n",
    "        BaseStep.__init__(self)\n",
    "        MetaStepMixin.__init__(self, wrapped)\n",
    "        ForceHandleOnlyMixin.__init__(self, cache_folder_when_no_handle)\n",
    "\n",
    "    def _transform_data_container(self, data_container: DataContainer, context: ExecutionContext) -> DataContainer:\n",
    "        new_expected_outputs_data_container = self.wrapped.handle_transform(\n",
    "            DataContainer(data_inputs=data_container.expected_outputs, current_ids=data_container.current_ids,\n",
    "                          expected_outputs=None),\n",
    "            context\n",
    "        )\n",
    "        data_container.set_expected_outputs(new_expected_outputs_data_container.data_inputs)\n",
    "\n",
    "        return data_container\n",
    "\n",
    "    def _fit_data_container(self, data_container: DataContainer, context: ExecutionContext) -> (BaseStep, DataContainer):\n",
    "        self.wrapped = self.wrapped.handle_fit(\n",
    "            DataContainer(data_inputs=data_container.expected_outputs, current_ids=data_container.current_ids,\n",
    "                          expected_outputs=None),\n",
    "            context\n",
    "        )\n",
    "\n",
    "        return self, data_container\n",
    "\n",
    "    def _fit_transform_data_container(self, data_container: DataContainer, context: ExecutionContext) -> (BaseStep, DataContainer):\n",
    "        self.wrapped, new_expected_outputs_data_container = self.wrapped.handle_fit_transform(\n",
    "            DataContainer(data_inputs=data_container.expected_outputs, current_ids=data_container.current_ids, expected_outputs=None),\n",
    "            context\n",
    "        )\n",
    "        data_container.set_expected_outputs(new_expected_outputs_data_container.data_inputs)\n",
    "\n",
    "        return self, data_container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand The DataContainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a typical step that expands the dimension of all the data inside the data container. ExpandDim sends the expanded data container to the wrapped step. \n",
    "ExpandDim returns the transformed expanded dim reduced to its original shape.\n",
    "\n",
    "This can be easily done in Neuraxle: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a step that inherits from MetaStepMixin, and BaseStep. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neuraxle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ec0819a690d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mneuraxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMetaStepMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataContainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExecutionContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneuraxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_container\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExpandedDataContainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mExpandDim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMetaStepMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'neuraxle'"
     ]
    }
   ],
   "source": [
    "from neuraxle.base import BaseStep, MetaStepMixin, DataContainer, ExecutionContext\n",
    "from neuraxle.data_container import ExpandedDataContainer\n",
    "import numpy as np\n",
    "\n",
    "class ExpandDim(MetaStepMixin, BaseStep):\n",
    "    def __init__(self, wrapped: BaseStep):\n",
    "        BaseStep.__init__(self)\n",
    "        MetaStepMixin.__init__(self, wrapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement the _will_process lifecycle method to expand the data inside the data container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _will_process(self, data_container, context):\n",
    "    data_container, context = BaseStep._will_process(self, data_container, context)\n",
    "    return ExpandedDataContainer.create_from(data_container), context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implement the _did_process lifecycle method to reduce the dimension of the data inside the data container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _did_process(self, data_container, context):\n",
    "    data_container = BaseStep._did_process(self, data_container, context)\n",
    "    return data_container.reduce_dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result looks like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpandDim(MetaStepMixin, BaseStep):\n",
    "    def __init__(self, wrapped: BaseStep):\n",
    "        BaseStep.__init__(self)\n",
    "        MetaStepMixin.__init__(self, wrapped)\n",
    "        \n",
    "    def _will_process(self, data_container, context):\n",
    "        data_container, context = BaseStep._will_process(self, data_container, context)\n",
    "        return ExpandedDataContainer.create_from(data_container), context\n",
    "\n",
    "    def _did_process(self, data_container, context):\n",
    "        data_container = BaseStep._did_process(self, data_container, context)\n",
    "        return data_container.reduce_dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reversible Pipeline\n",
    "\n",
    "Consider a step that can be reversible. For example, you might want to unnormalize predictions. This can be easily done with a step that inherits from TruncableSteps, and HandleOnlyMixin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a step that inherits from HandleOnlyMixin, and TruncableSteps. Initialize TruncableSteps with a preprocessing, and a postprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReversiblePreprocessingWrapper(HandleOnlyMixin, TruncableSteps):\n",
    "    def __init__(self, preprocessing_step, postprocessing_step):\n",
    "        HandleOnlyMixin.__init__(self)\n",
    "        TruncableSteps.__init__(self, [\n",
    "            (\"preprocessing_step\", preprocessing_step),\n",
    "            (\"postprocessing_step\", postprocessing_step)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement _fit_data_container: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_data_container(self, data_container: DataContainer, context: ExecutionContext) -> 'ReversiblePreprocessingWrapper':\n",
    "    self[\"preprocessing_step\"], data_container = \\\n",
    "        self[\"preprocessing_step\"].handle_fit_transform(data_container, context)\n",
    "    self[\"postprocessing_step\"] = \\\n",
    "        self[\"postprocessing_step\"].handle_fit(data_container, context)\n",
    "\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implement _transform_data_container: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _transform_data_container(self, data_container: DataContainer, context: ExecutionContext) -> DataContainer:\n",
    "    data_container = self[\"preprocessing_step\"].handle_transform(\n",
    "        data_container,\n",
    "        context.push(self[\"preprocessing_step\"])\n",
    "    )\n",
    "    data_container = self[\"postprocessing_step\"].handle_transform(\n",
    "        data_container,\n",
    "        context.push(self[\"postprocessing_step\"])\n",
    "    )\n",
    "\n",
    "    data_container = self[\"preprocessing_step\"].handle_inverse_transform(\n",
    "        data_container, \n",
    "        context.push(self[\"preprocessing_step\"])\n",
    "    )\n",
    "\n",
    "    return data_container\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Implement _fit_transform_data_container: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_transform_data_container(self, data_container: DataContainer, context: ExecutionContext) -> ('BaseStep', DataContainer):\n",
    "    self[\"preprocessing_step\"], data_container = self[\"preprocessing_step\"].handle_fit_transform(\n",
    "        data_container,\n",
    "        context.push(self[\"preprocessing_step\"])\n",
    "    )\n",
    "    self[\"postprocessing_step\"], data_container = self[\"postprocessing_step\"].handle_fit_transform(\n",
    "        data_container,\n",
    "        context.push(self[\"postprocessing_step\"])\n",
    "    )\n",
    "\n",
    "    data_container = self[\"preprocessing_step\"].handle_inverse_transform(\n",
    "        data_container,\n",
    "        context.push(self[\"preprocessing_step\"])\n",
    "    )\n",
    "\n",
    "    return self, data_container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results look like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReversiblePreprocessingWrapper(HandleOnlyMixin, TruncableSteps):\n",
    "    def __init__(self, preprocessing_step, postprocessing_step):\n",
    "        HandleOnlyMixin.__init__(self)\n",
    "        TruncableSteps.__init__(self, [\n",
    "            (\"preprocessing_step\", preprocessing_step),\n",
    "            (\"postprocessing_step\", postprocessing_step)\n",
    "        ])\n",
    "        \n",
    "    def _fit_transform_data_container(self, data_container: DataContainer, context: ExecutionContext) -> ('BaseStep', DataContainer):\n",
    "        self[\"preprocessing_step\"], data_container = self[\"preprocessing_step\"].handle_fit_transform(\n",
    "            data_container,\n",
    "            context.push(self[\"preprocessing_step\"])\n",
    "        )\n",
    "        self[\"postprocessing_step\"], data_container = self[\"postprocessing_step\"].handle_fit_transform(\n",
    "            data_container,\n",
    "            context.push(self[\"postprocessing_step\"])\n",
    "        )\n",
    "\n",
    "        data_container = self[\"preprocessing_step\"].handle_inverse_transform(\n",
    "            data_container,\n",
    "            context.push(self[\"preprocessing_step\"])\n",
    "        )\n",
    "\n",
    "        return self, data_container\n",
    "\n",
    "    def _transform_data_container(self, data_container: DataContainer, context: ExecutionContext) -> DataContainer:\n",
    "        data_container = self[\"preprocessing_step\"].handle_transform(\n",
    "            data_container,\n",
    "            context.push(self[\"preprocessing_step\"])\n",
    "        )\n",
    "        data_container = self[\"postprocessing_step\"].handle_transform(\n",
    "            data_container,\n",
    "            context.push(self[\"postprocessing_step\"])\n",
    "        )\n",
    "\n",
    "        data_container = self[\"preprocessing_step\"].handle_inverse_transform(\n",
    "            data_container, \n",
    "            context.push(self[\"preprocessing_step\"])\n",
    "        )\n",
    "\n",
    "        return data_container\n",
    "\n",
    "    def _fit_data_container(self, data_container: DataContainer, context: ExecutionContext) -> 'ReversiblePreprocessingWrapper':\n",
    "        self[\"preprocessing_step\"], data_container = \\\n",
    "            self[\"preprocessing_step\"].handle_fit_transform(data_container, context)\n",
    "        self[\"postprocessing_step\"] = \\\n",
    "            self[\"postprocessing_step\"].handle_fit(data_container, context)\n",
    "\n",
    "        return self"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neuraxle",
   "language": "python",
   "name": "neuraxle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
